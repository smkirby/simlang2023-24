{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Language, Lab 4, Iterated Bayesian Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simulation features a replication of the Reali & Griffiths iterated learning model of the evolution of frequency distributions, and is built around the Bayesian model of frequency learning/regularisation from Lab 3.  This simulation allows you to explore the effects of learning bias on cultural evolution. But before we get onto the model itself, we need to talk about log probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log, exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to log probabilities\n",
    "\n",
    "In the lectures I introduced Bayes’ Rule as a relationship between probabilities: the posterior is proportional to the product of the likelihood and the prior, and all three of these quantities are probabilities. Doing Bayesian models of learning therefore involves manipulating probabilities, numbers between 0 and 1. And some of these probabilities can be very small indeed, because they involve multiplying small numbers lots of times (consider, for instance, how small the probability is of getting 100 heads if you flip a fair coin 100 times: it’s 0.5 x 0.5 x 0.5 ... 100 times, or $0.5^{100}$ if you prefer. That’s a very small number.)\n",
    "\n",
    "As I said in the Lab 3 worksheet (go back and check if you need a refresher), working with small numbers on a computer can be a problem, because the computer cannot exactly represent real numbers (i.e. numbers we would write in decimal notation, e.g. numbers like 0.1, 3.147). There’s no way your computer can exactly represent every possible real number, so what it does instead is store numbers as accurately as it can, which involves introducing small rounding errors.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do you need to care about this? Well, if you are dealing with very very small numbers (as you might do if you were doing a Bayesian model which involves learning from lots of data) then the rounding errors become a real factor - for big numbers the rounding errors are so small (relative to the big numers) we don’t really care, but for very small numbers, the rounding errors might be relatively big. Worse, sometimes the computer will round a very very small number to 0, which can generate unexpected and hard-to-predict errors in your code (e.g. if you try to divide something by a very very small number which gets rounded to 0).  \n",
    "\n",
    "The solution to this is to have the computer work not with probabilities, but with *log probabilities*: we take our probabilities, take the log of those numbers, then carry on as before. We can convert log probabilities back to probabilities with the `exp` function, the inverse of the `log` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log(1))\n",
    "print(log(0.1))\n",
    "print(log(0.000001))\n",
    "print(exp(log(0.5)))\n",
    "print(exp(log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the code above, taking the log of a very small number turns it into a large negative number - these are still real numbers, so the computer still can’t represent them exactly, but in the log domain the rounding errors will be proportionately smaller for very small numbers and the rounding-to-0 problem won’t crop up. Then, if we want to see an actual probability, rather than a log probability, we can reverse this process, using the exp function, to get back raw probabilities. Jumping back and forth from logs can introduce rounding errors of its own, but it’s necessary to avoid the catastrophic rounding errors you can get if you just work with raw probabilities. \n",
    "\n",
    "Some basic arithmetic operations work a bit differently with logs. If you want to multiply two probabilities, you *add* their logarithms; if you want to divide one probability by another, you *subtract* the logarithm of one from another. And there is no direct equivalent of adding and subtracting in the log domain, which involves a little bit of fancy footwork in the code that you don’t have to worry about too much. The important thing is 1) to understand that the code is going to manipulate log probabilities and 2) this changes nothing conceptually, it’s just a matter of implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(0.5 * 0.5)\n",
    "print(exp(log(0.5) + log(0.5)))\n",
    "print(0.5 / 0.5)\n",
    "print(exp(log(0.5) - log(0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On to the code\n",
    "\n",
    "First, loading in the functions for random numbers and the beta distribution, plus some more that are specifically for doing stuff with logs. For instance, `logsumexp` (which we get from the `scipy.special` library allows us to do addition in the log domain (remember, just using the normal addition operator + with log probabilities is the equivalent of multiplying the raw probabilities). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from scipy.stats import beta\n",
    "from scipy.special import logsumexp\n",
    "from math import log, log1p, exp\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code starts with various bits and pieces which we need for working with logs and probability distributions. We define a function called `log_subtract` which allows us to do the equivalent of subtraction in the log domain (because if we just use normal subtraction, -, that’s equivalent to division). Then there are a couple of functions which we need for doing probabilistic sampling the log domain - `normalize_logprobs` will take a list of logs and normalise them for us (the equivalent of taking a list of pseudo-probabilities and rescaling them so they sum to 1, but in the log domain) and `log_roulette_wheel` takes a list of log probabilities and selects a random index from that list, with probability of any particular index being selected being given by its log probability. These are the log equivalents of `normalize_probs` and `roulette_wheel` from the Lab 3 code - they do exactly the same things, but with log probabilities rather than normal probabilities. As I said for the equivalent functions last week, *it is not important that you understand exactly how they work*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_subtract(x,y):\n",
    "    return x + log1p(-exp(y - x))\n",
    "\n",
    "def normalize_logprobs(logprobs):\n",
    "    logtotal = logsumexp(logprobs) #calculates the summed log probabilities\n",
    "    normedlogs = []\n",
    "    for logp in logprobs:\n",
    "        normedlogs.append(logp - logtotal) #normalise - subtracting in the log domain\n",
    "                                           #is equivalent to dividing in the normal domain\n",
    "    return normedlogs\n",
    "\n",
    "def log_roulette_wheel(normedlogs):\n",
    "    r=log(random.random()) #generate a random number between 0 and 1, then convert to log\n",
    "    accumulator = normedlogs[0] \n",
    "    for i in range(len(normedlogs)):\n",
    "        if r < accumulator:\n",
    "            return i\n",
    "        accumulator = logsumexp([accumulator, normedlogs[i + 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Lab 3, the main part of the code starts by laying out our hypothesis space, our grid of possible values of $\\theta$ or `pW1`. We will need two grids here - one of normal probabilities (because they are easier to look at) and one of log probabilities (since we are going to work with log probabilities when we do our calculations). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_granularity = 100\n",
    "grid_increment = 1 / grid_granularity\n",
    " \n",
    "# sets up the grid of possible probabilities to consider\n",
    "possible_pW1 = []\n",
    "for i in range(grid_granularity):\n",
    "    possible_pW1.append(grid_increment / 2 + (grid_increment * i))\n",
    "\n",
    "# sets up the grid of log probabilities\n",
    "possible_logpW1 = []\n",
    "for pW1 in possible_pW1:\n",
    "    possible_logpW1.append(log(pW1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the two grids (`possible_pW1` and `possible_logpW1`). Do they look like you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up come the various functions we need for Bayesian inference. Again, these are all the same as last week, but just set up to work with log probabilities rather than normal probabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_logprior(alpha):\n",
    "    logprior = []\n",
    "    for pW1 in possible_pW1:\n",
    "        logprior.append(beta.logpdf(pW1, alpha, alpha)) \n",
    "    return normalize_logprobs(logprior) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is exactly the same as the `calculate_prior` function from last week: you pass in an alpha parameter which determines the shape of the prior, it returns a list of values, one for each hypothesis in the hypothesis space, but the returned values are log probabilities rather than normal probabilities.   \n",
    "\n",
    "- Plot some different prior probability distributions - for example, try typing `plt.plot(possible_pW1, calculate_logprior(0.1))` to see the prior log-probability distribution over various values of `pW1` for the `alpha=0.1` prior. It should be the same shape as you saw last week, but the values up the y axis will be different - they are now log probabilities rather than probabilities, but all you need to care about is the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood and production\n",
    "\n",
    "As per the Lab 3 model, we are going to model data - sets of utterances - as a simple list of 0s and 1s: the 0s correspond to occurrences of word 0, the 1s correspond to occurrences of word 1. `loglikelihood` takes a log probability of word 1 being produced, and use that to calculate the probability of word 0 (which is 1 minus the probability of word 1). `logproduce` is the equivalent of `produce` last week, it generates some data based on a log-probability of producing word 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood(data, logpW1):\n",
    "    logpW0 = log_subtract(log(1), logpW1) #probability of w0 is 1-prob of w1\n",
    "    logprobs = [logpW0, logpW1]\n",
    "    loglikelihoods = []\n",
    "    for d in data:\n",
    "        loglikelihood_this_item = logprobs[d] #d will be either 0 or 1, \n",
    "                                              #so can use as index\n",
    "        loglikelihoods.append(loglikelihood_this_item)\n",
    "    return sum(loglikelihoods) #summing log probabilities = \n",
    "                               #multiply non-log probabilities\n",
    "    \n",
    "def logproduce(logpW1, n_productions):\n",
    "    logpW0 = log_subtract(log(1), logpW1)\n",
    "    logprobs = [logpW0, logpW1]\n",
    "    data = []\n",
    "    for p in range(n_productions):\n",
    "        data.append(log_roulette_wheel(logprobs))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test out the `logproduce` function - remember, you need to feed it a log probability, so decide on a probability for w1 and then convert it to log using the log function. Check that it works as expected based on what you did last week. \n",
    "- Next, check out the `loglikelihood` function - how does the likelihood of a set of data depend on the data and the probability of word 1? It should work in exactly the same way as last week. Remember that the likelihood function returns a log probability, so you can convert this to a probability using the `exp` function if you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logposterior(data, logprior):\n",
    "    posterior_logprobs = []\n",
    "    for i in range(len(possible_logpW1)):\n",
    "        logpW1 = possible_logpW1[i] \n",
    "        logp_h = logprior[i] #prior probability of this pW1\n",
    "        logp_d = loglikelihood(data, logpW1) #likelihood of data given this pW1\n",
    "        posterior_logprobs.append(logp_h + logp_d) #adding logs = \n",
    "                                                   #multiplying non-logs\n",
    "    return normalize_logprobs(posterior_logprobs) \n",
    "     \n",
    "def loglearn(data,prior):\n",
    "    posterior_logprobs = logposterior(data, prior)\n",
    "    selected_index = log_roulette_wheel(posterior_logprobs)\n",
    "    return possible_logpW1[selected_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the bits we need to calculate the posterior probability distribution, and therefore to do learning (by picking a hypothesis, a value of pW1, based on its posterior probability). You can verify that the posterior has the right sort of shape by doing something like this (which I adapted from the Lab 3 answer sheet): \n",
    "```python\n",
    "my_prior = calculate_logprior(1)\n",
    "my_data1 = [0] * 2 + [1] * 2\n",
    "my_data2 = [0] * 4 + [1] * 4\n",
    "my_data3 = [0] * 8 + [1] * 8\n",
    "print('data1 = ',my_data1)\n",
    "print('data2 = ',my_data2)\n",
    "print('data3 = ',my_data3)\n",
    "\n",
    "my_logposterior1 = logposterior(my_data1,my_prior)\n",
    "my_logposterior2 = logposterior(my_data2,my_prior)\n",
    "my_logposterior3 = logposterior(my_data3,my_prior)\n",
    "plt.plot(possible_pW1, my_logposterior1,'grey',label='p(theta|my_data1)')\n",
    "plt.plot(possible_pW1, my_logposterior2,'purple',label='p(theta|my_data2)')\n",
    "plt.plot(possible_pW1, my_logposterior3,'red',label='p(theta|my_data3)')\n",
    "plt.xlabel(\"theta\")\n",
    "plt.ylabel(\"logp(theta|data)\")\n",
    "plt.legend()\n",
    "```\n",
    "\n",
    "The numbers might look a bit different, because the y axis is logprobs, but the posterior should be highest where you expext it to be and low where you expect it to be low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterated learning\n",
    "\n",
    "At last, we have all the bits we need to do iterated learning: we can have a learner infer a value of `pW1` given some observed data, using the `loglearn` function, then we can have that individual produce data which another individual can learn from, using the `logproduce` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate(alpha, n_productions, starting_count_w1, generations):\n",
    "    prior = calculate_logprior(alpha)\n",
    "    pW1_accumulator = [] #we build up lists of our inferred pW1 at each generation\n",
    "    data_accumulator = [] #and number of produced word1 at each generation\n",
    "    data = [1] * starting_count_w1 + [0] * (n_productions - starting_count_w1)\n",
    "    for generation in range(generations):\n",
    "        logpW1 = loglearn(data, prior)\n",
    "        data = logproduce(logpW1, n_productions)\n",
    "        pW1_accumulator.append(exp(logpW1)) #will convert the inferred pW1 to a normal probability for you!\n",
    "        data_accumulator.append(sum(data))\n",
    "    return pW1_accumulator, data_accumulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run a simulation using something like:\n",
    "\n",
    "```python\n",
    "pW1_by_generation, data_by_generation = iterate(0.1, 10, 5, 20)\n",
    "``` \n",
    "\n",
    "This will run the simulation for 20 generations, using a prior defined by alpha=0.1, each learner observes 10 data points before inferring pW1, and the initial language consists of 5 examples of word 1 (and therefore 5 of word 0). It returns two  values (this is the first time we've had a function do that, it's quote handy): a generation-by-generation record of the inferred values of pW1, and the data produced at each generation (specified as a number of occurences of word 1). It's worth plotting these values as a graph over time, but also looking at the histogram of the values to get a sense of how they are distributed overall. \n",
    "\n",
    "We can plot a simple line graph like this:\n",
    "```python\n",
    "pW1_by_generation, data_by_generation = iterate(0.1, 10, 5, 20)\n",
    "\n",
    "plt.plot(pW1_by_generation)\n",
    "plt.xlabel(\"generations\")\n",
    "plt.ylabel(\"theta\")\n",
    "```\n",
    "\n",
    "And you can get a histogram of the `pW1` values across the entire simulation run like this:\n",
    "```python\n",
    "pW1_by_generation, data_by_generation = iterate(0.1, 10, 5, 1000)\n",
    "plt.hist(pW1_by_generation)\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel(\"theta\")\n",
    "plt.ylabel(\"frequency\")\n",
    "```\n",
    "The histograms might look better if you increase the number of generations *a lot*, like to 1000, to simulate a very long chain of transmission.\n",
    "\n",
    "If you want to run a bunch of iterated learning chains, say 10, and plot them all on the same graph, you can do something like this:\n",
    "```python\n",
    "for i in range(10):\n",
    "    pW1_by_generation, data_by_generation = iterate(0.1, 10, 5, 20)\n",
    "    plt.plot(pW1_by_generation)\n",
    "plt.xlabel(\"generations\")\n",
    "plt.ylabel(\"theta\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "Once you are happy that you understand that the log version of the code doesn't do anything different to the Lab 3 versions, and that you understand how iterated learning works, try these questions:\n",
    "\n",
    "1. One of Reali & Griffiths’s main points was that studying learning in a single individual can be a bad way to discover their prior bias, particularly if you give them lots of data which swamps this prior bias - given enough data, learners with quite different priors look the same. Can you reproduce this effect using this code, or the Lab 3 code?\n",
    "2. Iterated learning can potentially give a clearer picture of prior bias. Try running some simulations for 10 generations, with 10 data points passed from generation to generation, starting each simulation with 5 instances of w1 and 5 of w0. How does changing the prior change the results?  Try alpha=0.1, alpha=1, and alpha=5. Are the differences between different priors obvious after generation 1, or do they become more apparent over generations? Try running some very long chains (e.g. 1000 generations) with different priors and plotting histograms of the `pW1` values - can you see the effect of different priors here?\n",
    "3. Now try messing with the amount of data that is passed from generation to generation (remember to change the starting count of the w1 so you can compare between the different data set sizes fairly). What happens if you pass more data between generations? What happens if you pass less? What happens if you pass no data from generation to generation? What would this latter setting correspond to in the real world?\n",
    "4. If iterated learning is a model of language transmission in the real-world, what do these results imply about the kinds of languages we see in the wild, and how they relate to the prior biases of real language learners?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
